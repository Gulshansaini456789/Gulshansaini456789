Practical no 7
Create a database design for Microservices an application using the database.

Choosing a Data Store
There are many risks associated with embracing a 1.0-level technology. The ecosystem is generally immature, so support for your favorite things may be lacking or missing entirely. Tooling and integration and overall developer experience are often high-friction. Despite the long and storied history of
.NET, .NET Core (and especially the associated tooling) should still be treated like a brand new 1.0 product.
One of things we might run into when trying to pick a data store that is compatible with EF Core is a lack of available providers. While this list will likely have grown by the time you read this, at the time this chapter was written, the following providers were available for EF Core:
SQL Server 
SQLite 
Postgres 
IBM databases 
MySQL
SQL Server Lite
In-memory provider for testing 
Oracle 
For databases that aren’t inherently compatible with the Entity Framework relational model, like MongoDB, Neo4j, Cassandra, etc., you should be able to find client libraries available that will work with .NET Core. Since most of these databases expose simple RESTful APIs, you should still be able to use them even if you have to write your own client.
Because of my desire to keep everything as cross-platform as possible throughout this book, I decided to use Postgres instead of SQL Server to accommodate readers working on Linux or Mac workstations. Postgres is also easily installed on Windows.


Building a Postgres Repository
In order to get something running and focus solely on the discipline and code required to stand up a simple service, we used an in-memory repository that didn’t amount to much more than a fake that aided us in writing tests.
In this section we’re going upgrade our location service to work with Postgres. To do this we’re going to create a new repository implementation that encapsulates the PostgreSQL client communication. Before we get to the implementation code, let’s revisit the interface for our location repository.

Example 1. ILocationRecordRepository.cs
using System;
using System.Collections.Generic;
namespace StatlerWaldorfCorp.LocationService.Models { public interface ILocationRecordRepository {
LocationRecord Add(LocationRecord locationRecord); LocationRecord Update(LocationRecord locationRecord); LocationRecord Get(Guid memberId, Guid recordId); LocationRecord Delete(Guid memberId, Guid recordId);

LocationRecord GetLatestForMember(Guid memberId);

ICollection<LocationRecord> AllForMember(Guid memberId);
}
}

The location repository exposes standard CRUD functions like Add, Update, Get, and Delete. In addition, this repository exposes methods to obtain the latest location entry for a member as well as the entire location history for a member.
The purpose of the location service is solely to track location data, so you’ll notice that there is no reference to team membership at all in this interface.

Creating a Database Context
The next thing we’re going to do is create a database context. This class will serve as a wrapper around the base DbContext class we get from Entity Framework Core. Since we’re dealing with locations, we’ll call our context class LocationDbContext.
If you’re not familiar with Entity Framework or EF Core, the database context acts as the gateway between your database-agnostic model class (POCOs, or Plain-Old C# Objects) and the real database. For more information on EF Core, check out Microsoft’s documentation. We could probably spend another several chapters doing nothing but exploring its details, but since we’re trying to stay focused on cloud-native applications and services, we’ll use just enough EF Core to build our services.
The pattern for using a database context is to create a class that inherits from it that is specific to your model. In our case, since we’re dealing with locations, we’ll create a LocationDbContext class.
Example 2. LocationDbContext.cs
using Microsoft.EntityFrameworkCore;
using StatlerWaldorfCorp.LocationService.Models; using Npgsql.EntityFrameworkCore.PostgreSQL;

namespace StatlerWaldorfCorp.LocationService.Persistence
{
public class LocationDbContext : DbContext
{
public LocationDbContext( DbContextOptions<LocationDbContext> options) :
base(options)
{
}

protected override void OnModelCreating( ModelBuilder modelBuilder)
{
base.OnModelCreating(modelBuilder); modelBuilder.HasPostgresExtension("uuid-ossp");
}

public DbSet<LocationRecord> LocationRecords {get; set;}
}
}

Here we can use the ModelBuilder and DbContextOptions classes to perform any additional setup we need on the context. In our case, we’re ensuring that our model has the uuid-ossp Postgres extension to support the member ID field.



Implementing the Location Record Repository Interface
Now that we have a context through which other classes can use to communicate with the database, we can create a real implementation of the ILocationRecordRepository interface. This real implementation will take an instance of LocationDbContext as a constructor parameter. This sets us up nicely to configure this context with environment-supplied connection strings when deploying for real and with mocks or in-memory providers when testing.
Example 3 contains the code for the LocationRecordRepository class
Example 3. LocationRecordRepository.cs
using System; using System.Linq;
using System.Collections.Generic;
using StatlerWaldorfCorp.LocationService.Models;

namespace StatlerWaldorfCorp.LocationService.Persistence
{
public class LocationRecordRepository : ILocationRecordRepository
{
private LocationDbContext context;

public LocationRecordRepository(LocationDbContext context)
{
this.context = context;
}

public LocationRecord Add(LocationRecord locationRecord)
{
this.context.Add(locationRecord); this.context.SaveChanges(); return locationRecord;
}

public LocationRecord Update(LocationRecord locationRecord)
{
this.context.Entry(locationRecord).State = EntityState.Modified;
this.context.SaveChanges(); return locationRecord;
}

public LocationRecord Get(Guid memberId, Guid recordId)
{
return this.context.LocationRecords
.Single(lr => lr.MemberID == memberId &&
lr.ID == recordId);
}

public LocationRecord Delete(Guid memberId, Guid recordId)
{
LocationRecord locationRecord = this.Get(memberId, recordId);
this.context.Remove(locationRecord); this.context.SaveChanges();
return locationRecord;

}

public LocationRecord GetLatestForMember(Guid memberId)
{
LocationRecord locationRecord = this.context.LocationRecords.
Where(lr => lr.MemberID == memberId). OrderBy(lr => lr.Timestamp).
Last();
return locationRecord;
}

public ICollection<LocationRecord> AllForMember(Guid memberId)
{
return this.context.LocationRecords.
Where(lr => lr.MemberID == memberId). OrderBy(lr => lr.Timestamp).
ToList();
}
}
}

The code here is pretty straightforward. Any time we make a change to the database, we call SaveChanges on the context. If we need to query, we use the LINQ expression syntax where we can combine Where and OrderBy to filter and sort the results.
When we do an update, we need to flag the entity we’re updating as a modified entry so that Entity Framework Core knows how to generate an appropriate SQL UPDATE statement for that record. If we don’t modify this entry state, EF Core won’t know anything has changed and so a call
to SaveChanges will do nothing.
The next big trick in this repository is injecting the Postgres-specific database context. To make this happen, we need to add this repository to the dependency injection system in the ConfigureServices  method of our Startup class.
Example 4. ConfigureServices method in Startup.cs

public void ConfigureServices(IServiceCollection services)
{
services.AddEntityFrameworkNpgsql()
.AddDbContext<LocationDbContext>(options => options.UseNpgsql(Configuration));
services.AddScoped<ILocationRecordRepository, LocationRecordRepository>();
services.AddMvc();
}

First we want to use the AddEntityFrameworkNpgsql extension method exposed by the Postgres EF Core provider. Next, we add our location repository as a scoped service. When we use the AddScoped method, we’re indicating that every new request made to our service gets a newly create instance of this repository.
Configuring a Postgres Database Context
The repository we built earlier requires some kind of database context in order to function. The database context is the core primitive of Entity Framework Core. To create a database context for the location model, we just need to create a class that inherits from DbContext. I’ve also included a DbContextFactory because that can sometimes make running the Entity Framework Core command-line tools simpler:

using Microsoft.EntityFrameworkCore;
using Microsoft.EntityFrameworkCore.Infrastructure; using StatlerWaldorfCorp.LocationService.Models; using Npgsql.EntityFrameworkCore.PostgreSQL;

namespace StatlerWaldorfCorp.LocationService.Persistence
{
public class LocationDbContext : DbContext
{
public LocationDbContext(
DbContextOptions<LocationDbContext> options) :base(options)
{
}

protected override void OnModelCreating( ModelBuilder modelBuilder)
{
base.OnModelCreating(modelBuilder); modelBuilder.HasPostgresExtension("uuid-ossp");
}

public DbSet<LocationRecord> LocationRecords {get; set;}
}

		public class LocationDbContextFactory : IDbContextFactory<LocationDbContext>
{
public LocationDbContext Create(DbContextFactoryOptions options)
{
var optionsBuilder =
new DbContextOptionsBuilder<LocationDbContext>(); var connectionString =
Startup.Configuration
.GetSection("postgres:cstr").Value; optionsBuilder.UseNpgsql(connectionString);

return new LocationDbContext(optionsBuilder.Options);
}
}
}

With a new database context, we need to make it available for dependency injection so that the location repository can utilize it:

public void ConfigureServices(IServiceCollection services)
{
var transient = true;
if (Configuration.GetSection("transient") != null) { transient = Boolean.Parse(Configuration
.GetSection("transient").Value);
}
if (transient) { logger.LogInformation(
"Using transient location record repository."); services.AddScoped<ILocationRecordRepository,
InMemoryLocationRecordRepository>();
} else {
var connectionString = Configuration.GetSection("postgres:cstr").Value;

services.AddEntityFrameworkNpgsql()
.AddDbContext<LocationDbContext>(options => options.UseNpgsql(connectionString));
logger.LogInformation(
"Using '{0}' for DB connection string.", connectionString);
services.AddScoped<ILocationRecordRepository, LocationRecordRepository>();
}

services.AddMvc();
}
The calls to AddEntityFrameworkNpgsql and AddDbContext are the magic that makes everything happen here.
With a context configured for DI, our service should be ready to run, test, and accept EF Core command-line parameters like the ones we need to execute migrations. When building your own database-backed services, you can also use the EF Core command-line tools to reverse-engineer migrations from existing database schemas. 
Exercising the Data Service 
Running the data service should be relatively easy. The first thing we’re going to need to do is spin up a running instance of Postgres. If you were paying attention to the wercker.yml file for the location service that sets up the integration tests, then you might be able to guess at the docker run command to start Postgres with our preferred parameters: 

This starts the Postgres Docker image with the name some-postgres (this will be important shortly). To verify that we can connect to Postgres, we can run the following Docker command to launch psql: 

With the database up and running, we need a schema. The tables in which we expect to store the migration metadata and our location records don’t yet exist. To put them in the database, we just need to run an EF Core command from the location service’s project directory. Note that we’re also setting environment variables that we’ll need soon:

At this point Postgres is running with a valid schema and it’s ready to start accepting commands from the location service. Here’s where it gets a little tricky. If we’re going to run the location service from inside a Docker image, then referring to the Postgres server’s host as localhost won’t work —because that’s the host inside the Docker image. What we need is for the location service to reach out of its container and then into the Postgres container. We can do this with a container link that creates a virtual hostname (we’ll call it postgres), but we’ll need to change our environment variable before launching the Docker image:

Now that we’ve linked the service’s container to the Postgres container via the postgres hostname, the location service should have no trouble connecting to the database. To see this all in action, let’s submit a location record (as usual, take the line feeds out of this command when you type it):

Take a look at the trace output from your running Docker image for the location service. You should see some very useful Entity Framework trace data explaining what happened. The service performed a SQL INSERT, so things are looking promising:


Let’s ask the service for this fictitious member’s location history:





The corresponding Entity Framework trace looks like this:

Just to be double sure, let’s query the latest endpoint to make sure we still get what we expect to see:

Finally, to prove that we really are using real database persistence and that this isn’t just a random fluke, use docker ps and docker kill to locate the Docker process for the location service and kill it. Restart it using the exact same command you used before. You should now be able to query the location service and get the exact same data you had before. Of course, once you stop the Postgres container you’ll permanently lose that data.